{
 "metadata": {
  "name": "",
  "signature": "sha256:a2ee4ff223a27a99e1356a980c3e3f630ac5afd94ba5bf9f9354e9f0ff7cd1a7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Building a movie recommender using Collaborative Filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook explains how to use the [MovieLens dataset](http://grouplens.org/datasets/movielens/) to build a movie recommender using [collaborative filtering](https://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering) with [Spark's Alternating Least Saqures](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) implementation. It is organised in two parts. The first one is about getting and parsing movies and ratings data into Spark RDDs. The second is about building the recommender and persisting it for later use in our on-line recommender system.    "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting and processing the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to build an on-line movie recommender using Spark, we need to have our model data as preprocessed as possible. Parsing the dataset and building the model everytime a new recommendation needs to be done is not the best of the strategies."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The list of task we can pre-compute includes:  \n",
      "\n",
      "- Loading and parsing the dataset. Persisting the resulting RDD for later use.  \n",
      "- Building the recommender model using the complete dataset. Persist the dataset for later use.  \n",
      "\n",
      "This notebook explains the first of these tasks.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "File download"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GroupLens Research has collected and made available rating data sets from the [MovieLens web site](http://movielens.org). The data sets were collected over various periods of time, depending on the size of the set. They can be found [here](http://grouplens.org/datasets/movielens/).   "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In our case, we will use the latest datasets:  \n",
      "\n",
      "- Small: 100,000 ratings and 2,488 tag applications applied to 8,570 movies by 706 users. Last updated 4/2015.  \n",
      "- Full: 21,000,000 ratings and 470,000 tag applications applied to 27,000 movies by 230,000 users. Last updated 4/2015.  \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
      "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also need to define download locations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "datasets_path = os.path.join('..', 'datasets')\n",
      "\n",
      "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
      "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can proceed with both downloads."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "\n",
      "small_f = urllib.urlretrieve (small_dataset_url, small_dataset_path)\n",
      "complete_f = urllib.urlretrieve (complete_dataset_url, complete_dataset_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both of them are zip files containing a folder with ratings, movies, etc. We need to extract them into its individual folders so we can use each file later on.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import zipfile\n",
      "\n",
      "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
      "    z.extractall(datasets_path)\n",
      "\n",
      "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
      "    z.extractall(datasets_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Loading and parsing datasets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "No we are ready to read in each of the files and create an RDD consisting of parsed lines.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each line in the ratings dataset (`ratings.csv`) is formatted as:  \n",
      "\n",
      "`userId,movieId,rating,timestamp`  \n",
      "\n",
      "Each line in the movies (`movies.csv`) dataset is formatted as:  \n",
      "\n",
      "`movieId,title,genres`  \n",
      "\n",
      "Were *genres* has the format:  \n",
      "\n",
      "`Genre1|Genre2|Genre3...`\n",
      "\n",
      "The tags file (`tags.csv`) has the format:  \n",
      "\n",
      "`userId,movieId,tag,timestamp`  \n",
      "\n",
      "And finally, the `links.csv` file has the format:  \n",
      "\n",
      "`movieId,imdbId,tmdbId`  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The format of these files is uniform and simple, so we can use Python [`split()`](https://docs.python.org/2/library/stdtypes.html#str.split) to parse their lines once they are loaded into RDDs. Parsing the movies and ratings files yields two RDDs:  \n",
      "\n",
      "* For each line in the ratings dataset, we create a tuple of `(UserID, MovieID, Rating)`. We drop the *timestamp* because we do not need it for this recommender.  \n",
      "* For each line in the movies dataset, we create a tuple of `(MovieID, Title)`. We drop the *genres* because we do not use them for this recommender.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So let's load the raw ratings data. We need to filter out the header, included in each file.    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
      "\n",
      "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
      "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can parse the raw data into a new RDD.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
      "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For illustrative purposes, we can take the first few lines of our RDD to see the result. In the final script we don't call any Spark action (e.g. `take`) until needed, since they trigger actual computations in the cluster.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small_ratings_data.take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[(u'1', u'6', u'2.0'), (u'1', u'22', u'3.0'), (u'1', u'32', u'2.0')]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We proceed in a similar way with the `movies.csv` file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
      "\n",
      "small_movies_raw_data = sc.textFile(small_movies_file)\n",
      "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
      "\n",
      "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
      "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
      "    \n",
      "small_movies_data.take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[(u'1', u'Toy Story (1995)'),\n",
        " (u'2', u'Jumanji (1995)'),\n",
        " (u'3', u'Grumpier Old Men (1995)')]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Building a recommender using Alternating Least Squares"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Collaborative Filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In Collaborative filtering we make predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption is that if a user A has the same opinion as a user B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a user chosen randomly.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The image below (from [Wikipedia](https://en.wikipedia.org/?title=Collaborative_filtering)) shows an example of collaborative filtering. At first, people rate different items (like videos, images, games). Then, the system makes predictions about a user's rating for an item not rated yet. The new predictions are built upon the existing ratings of other users with similar ratings with the active user. In the image, the system predicts that the user will not like the video.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![collaborative filtering](https://upload.wikimedia.org/wikipedia/commons/5/52/Collaborative_filtering.gif)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Spark MLlib library for Machine Learning provides a [Collaborative Filtering](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) implementation by using [Alternating Least Squares](http://dl.acm.org/citation.cfm?id=1608614). The implementation in MLlib has the following parameters:  \n",
      "\n",
      "- numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).  \n",
      "- rank is the number of latent factors in the model.  \n",
      "- iterations is the number of iterations to run.  \n",
      "- lambda specifies the regularization parameter in ALS.  \n",
      "- implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.  \n",
      "- alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.  \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Determining parameters using the small dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to determine the best ALS parameters, we will use the small dataset. We need first to split it into train, validation, and test datasets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0L)\n",
      "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
      "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can proceed with the training phase. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.recommendation import ALS\n",
      "import math\n",
      "\n",
      "seed = 5L\n",
      "iterations = 5\n",
      "regularization_parameter = 0.1\n",
      "ranks = [4, 8, 12]\n",
      "errors = [0, 0, 0]\n",
      "err = 0\n",
      "tolerance = 0.02\n",
      "\n",
      "min_error = float('inf')\n",
      "best_rank = -1\n",
      "best_iteration = -1\n",
      "for rank in ranks:\n",
      "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
      "                      lambda_=regularization_parameter)\n",
      "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
      "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
      "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
      "    errors[err] = error\n",
      "    err += 1\n",
      "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
      "    if error < min_error:\n",
      "        min_error = error\n",
      "        best_rank = rank\n",
      "\n",
      "print 'The best model was trained with rank %s' % best_rank"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For rank 4 the RMSE is 0.975984762548\n",
        "For rank 8 the RMSE is 0.964965122754"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "For rank 12 the RMSE is 0.980927007935"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The best model was trained with rank 8\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But let's explain this a little bit. First, let's have a look at how our predictions look.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions.take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "[((257, 4018), 3.3151217401555773),\n",
        " ((538, 4018), 2.5210811083300704),\n",
        " ((674, 4018), 2.4921510265854216)]"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basically we have the UserID, the MovieID, and the Rating, as we have in our ratings dataset. In this case the predictions third element, the rating for that movie and user, is the predicted by our ALS model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we join these with our validation data (the one that includes ratings) and the result looks as follows:  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rates_and_preds.take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[((558, 788), (3.0, 2.731767282376123)),\n",
        " ((176, 3550), (4.5, 3.58503477932916)),\n",
        " ((302, 3908), (1.0, 2.5929188005469768))]"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To that, we apply a squared difference and the we use the `mean()` action to get the MSE and apply `sqrt`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we test the selected model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
      "                      lambda_=regularization_parameter)\n",
      "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
      "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
      "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
      "    \n",
      "print 'For testing data the RMSE is %s' % (error)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For testing data the RMSE is 0.986836601471\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using the complete dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to build our recommender model, we will use the complete dataset. We are not going to evaluate this model since we a "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can train de model using our training split.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now evaluate using the testing data.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Persisting the model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to persist the base model for later use in our on-line recommendations.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save and load model\n",
      "model.save(sc, \"myModelPath\")\n",
      "same_model = MatrixFactorizationModel.load(sc, \"myModelPath\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}